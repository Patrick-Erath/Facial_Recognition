{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import select\n",
    "from skimage import feature as ft\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "from sklearn import mixture\n",
    "\n",
    "importpath   = \"../../../Dataset/\"\n",
    "testrainpath = [\"Testing\", \"Training\"]\n",
    "namespath    = [\"/Abed/\", \"/Daniel/\", \"/Jules/\", \"/Lea/\", \"/Patrick/\"]\n",
    "rescaledpath = \"Rescaled\"\n",
    "croppedpath  = \"Cropped\"\n",
    "\n",
    "meta_data = {0: 'Abed', 1: 'Daniel', 2: 'Jules', 3: 'Lea', 4: 'Patrick'}\n",
    "\n",
    "def get_data(isCropped=True):\n",
    "\n",
    "    # Test train data\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    X_test  = []\n",
    "    Y_test  = []\n",
    "\n",
    "    # define both import paths\n",
    "    testpath = importpath+testrainpath[0]\n",
    "    trainpath= importpath+testrainpath[1]\n",
    "\n",
    "    for i, npath in enumerate(namespath):\n",
    "\n",
    "        if isCropped:\n",
    "            testfolder = testpath + croppedpath + npath\n",
    "            trainfolder= trainpath+ croppedpath + npath\n",
    "        else:\n",
    "            testfolder = testpath + rescaledpath + npath\n",
    "            trainfolder= trainpath+ rescaledpath + npath\n",
    "\n",
    "        for imgname in os.listdir(testfolder):\n",
    "\n",
    "            img = cv2.imread(testfolder+imgname)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            X_test.append(img)\n",
    "            Y_test.append(i)\n",
    "\n",
    "        for imgname2 in os.listdir(trainfolder):\n",
    "\n",
    "            img = cv2.imread(trainfolder+imgname2)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            X_train.append(img)\n",
    "            Y_train.append(i)\n",
    "\n",
    "#     # once the data is saved, shuffle it\n",
    "#     X_train , Y_train = shuffle(X_train, Y_train)\n",
    "#     X_test  , Y_test  = shuffle(X_test, Y_test)\n",
    "\n",
    "    return np.asarray(X_train), np.asarray(Y_train), np.asarray(X_test), np.asarray(Y_test), meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift(img):\n",
    "\n",
    "    # copy image\n",
    "    img_disp = img.copy()\n",
    "    # convert to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_disp = cv2.cvtColor(img_disp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # create a SIFT object\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # detect SIFT features, with no masks\n",
    "    keypoints = sift.detect(img, None)\n",
    "    \n",
    "    p = []\n",
    "    keypoints3, descriptors = sift.compute(img, keypoints)\n",
    "    for k in keypoints3:\n",
    "        p.append(k.pt)\n",
    "\n",
    "    # draw the keypoints\n",
    "    cv2.drawKeypoints(img, keypoints, img_disp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# #     display\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.subplot(121), plt.imshow(img)\n",
    "#     plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(122), plt.imshow(img_disp)\n",
    "#     plt.title(\"SIFT Features\"), plt.xticks([]), plt.yticks([])\n",
    "#     plt.show()\n",
    "\n",
    "#     # num of SIFT keypoints\n",
    "#     print('Num keypoints: ' + str(len(keypoints)))\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "# Get croppped image coordinates in original image (x,y in top left corner)\n",
    "def get_coordinates(img_rescaled, img_cropped):\n",
    "    # imgggg_rgb = cv2.imread(\"../../../Dataset/TrainingRescaled/Abed/scale1_0.jpeg\")\n",
    "    # img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    # template = cv2.imread(\"../../../Dataset/TrainingCropped/Abed/scale1_0.jpeg\", 0)\n",
    "    img_rescaled = cv2.cvtColor(img_rescaled, cv2.COLOR_BGR2GRAY)\n",
    "    img_cropped = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
    "    w, h = img_cropped.shape[::-1]\n",
    "    res = cv2.matchTemplate(img_rescaled, img_cropped, cv2.TM_SQDIFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    top_left = min_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    x = top_left[0]\n",
    "    y = top_left[1]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def make_patch(img,img_cropped, size, k):\n",
    "    # get patch centers\n",
    "    patch_centers = []\n",
    "    for i in k:\n",
    "        patch_centers.append(i)\n",
    "\n",
    "    # extract patches\n",
    "    patch_images = []\n",
    "    patch_size = size\n",
    "    count=0\n",
    "    for center in patch_centers:\n",
    "        patchXStart = int(center[0] - (patch_size / 2.))\n",
    "        patchYStart = int(center[1] - (patch_size / 2.))\n",
    "        if((center[0] + patch_size)>img_cropped.shape[1] or (center[0] - patch_size)<0 or (center[1] + patch_size)>img_cropped.shape[0] or (center[1] - patch_size)<0 ):\n",
    "            count+=1\n",
    "            x,y = get_coordinates(img, img_cropped)\n",
    "            patchXStart += x\n",
    "            patchYStart += y\n",
    "            patch_images.append(img[patchXStart:patchXStart + patch_size, patchYStart:patchYStart + patch_size])\n",
    "        else:\n",
    "            patch_images.append(img_cropped[patchXStart:patchXStart + patch_size, patchYStart:patchYStart + patch_size])\n",
    "\n",
    "#     print(\"count= \" , count)\n",
    "#     # display\n",
    "#     for im in patch_images:\n",
    "#         plt.figure(figsize=(5, 5))\n",
    "#         plt.imshow(im)\n",
    "#         plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "#         plt.show()\n",
    "    return patch_images\n",
    "\n",
    "\n",
    "# ----- HoG Function ----- #\n",
    "def rgb2gray(im):\n",
    "    gray = im[:, :, 0] * 0.2989 + im[:, :, 1] * 0.5870 + im[:, :, 2] * 0.1140\n",
    "    return gray\n",
    "\n",
    "def hog_features(imgs, cells):\n",
    "    train_x = []\n",
    "    for data in imgs:\n",
    "        gray = rgb2gray(data) / 255.0\n",
    "        x = ft.hog(gray, orientations=9, pixels_per_cell=(2, 2),\n",
    "                   cells_per_block=(cells, cells))\n",
    "        train_x.append(x)\n",
    "    return train_x\n",
    "\n",
    "def get_hog(patches, cell_size):\n",
    "    hog_patches = []\n",
    "    for patch in patches:\n",
    "        hog_ft = hog_features(patch, cell_size)\n",
    "        hog_patches.append(hog_ft)\n",
    "    hog_flat = []\n",
    "    for h in hog_patches:\n",
    "        hog_flat.append(np.asarray(h).flatten().ravel())\n",
    "    h = np.asarray(hog_flat)\n",
    "    return h\n",
    "\n",
    "def get_em(x_train_hog, y_train, x_test_hog, y_test):\n",
    "    \n",
    "    '''\n",
    "    Covariance is spherical since it's the fastest one\n",
    "    With Full Covariance, device was running out of memory\n",
    "    '''\n",
    "    print(\"GMM\")\n",
    "    gmm = mixture.GaussianMixture(n_components=5, covariance_type='spherical')\n",
    "    fit_data = gmm.fit(x_train_hog)\n",
    "    labels = gmm.predict(x_test_hog)\n",
    "    accuracy = (np.mean(y_test == labels))\n",
    "    \n",
    "    return fit_data, accuracy, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM\n",
      "Validation Accuracy :  0.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "   # Load Cropped Data\n",
    "\n",
    "    cropped_data = get_data(isCropped=True)\n",
    "    X_train_cropped = cropped_data[0]\n",
    "    Y_train_cropped = cropped_data[1]\n",
    "    X_test_cropped = cropped_data[2]\n",
    "    Y_test_cropped = cropped_data[3]\n",
    "    metadata_cropped = cropped_data[4]\n",
    "    \n",
    "    # Load Original Data\n",
    "    \n",
    "    data = get_data(isCropped=False)\n",
    "    X_train = data[0]\n",
    "    Y_train = data[1]\n",
    "    X_test = data[2]\n",
    "    Y_test = data[3]\n",
    "    metadata = data[4]\n",
    "\n",
    "    # Train Images\n",
    "\n",
    "    patches_train_list = []\n",
    "    for i in range(0, len(X_train_cropped)):\n",
    "        cropped_img = X_train_cropped[i]\n",
    "        original_img = X_train[i]\n",
    "        kp = sift(cropped_img)\n",
    "        patches_train = make_patch(img=original_img,img_cropped=cropped_img, size=15, k=kp[:15])\n",
    "        patches_train_list.append(patches_train)\n",
    "\n",
    "\n",
    "    # Test Images\n",
    "\n",
    "    patches_test_list = []\n",
    "    for i in range(0, len(X_test_cropped)):  \n",
    "        cropped_img_test = X_test_cropped[i]\n",
    "        original_img_test = X_test[i]\n",
    "        kp = sift(cropped_img_test)\n",
    "        patches_test = make_patch(img=original_img_test,img_cropped=cropped_img_test, size=15, k=kp[:15])\n",
    "        patches_test_list.append(patches_test)\n",
    "\n",
    "    # HOG - Training Patches\n",
    "\n",
    "    h_3_train = get_hog(patches_train_list, 3)\n",
    "    h_4_train = get_hog(patches_train_list, 4)\n",
    "    h_5_train = get_hog(patches_train_list, 5)\n",
    "\n",
    "    # HOG - Testing Patches\n",
    "\n",
    "    h_3_test = get_hog(patches_test_list, 3)\n",
    "    h_4_test = get_hog(patches_test_list, 4)\n",
    "    h_5_test = get_hog(patches_test_list, 5)\n",
    "    \n",
    "    # Run EM\n",
    "    \n",
    "    fit_data, accuracy, labels = get_em(h_3_train, Y_train, h_3_test, Y_test)\n",
    "    print(\"Validation Accuracy : \" ,accuracy)\n",
    "    \n",
    "    # Create the confusion matrix\n",
    "    conf = confusion_matrix(Y_test, labels)\n",
    "\n",
    "    # display\n",
    "    plt.figure()\n",
    "    plt.imshow(conf)\n",
    "    plt.title(\"Confusion Matrix\"), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
